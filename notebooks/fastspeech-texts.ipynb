{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fairseq -q\n!pip install g2p_en -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface import TTSHubInterface\n\n\nclass TTSModel:\n    def __init__(self):\n        models, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n            \"facebook/fastspeech2-en-ljspeech\",\n            arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False}\n        )\n        self.model = models[0]\n        self.task = task\n        \n        TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\n        self.generator = self.task.build_generator(models, cfg) \n        \n    def get_sample(self, text):\n        return TTSHubInterface.get_model_input(self.task, text)\n    \n    def get_durations(self, sample):\n        # encoder.forward args: src_tokens, src_lengths=None, speaker=None, durations=None, pitches=None, energies=None,\n        x, x_post, out_lens, log_dur_out, pitch_out, energy_out = self.model.encoder(**sample[\"net_input\"])\n        return torch.exp(log_dur_out)\n    \n    def simple_change(self, text, dur_factor=1.):\n        sample = self.get_sample(text)\n        durs = self.get_durations(sample)\n        \n        durs[sample[\"net_input\"][\"src_tokens\"] == 11] *= dur_factor # 11 == ','\n        sample[\"net_input\"][\"durations\"] = durs.long()\n        \n        return sample\n    \n    def get_wav(self, sample):\n        bsz, max_src_len = sample[\"net_input\"][\"src_tokens\"].size()\n        n_frames_per_step = self.model.encoder.n_frames_per_step\n        out_dim = self.model.encoder.out_dim\n        raw_dim = out_dim // n_frames_per_step\n        \n        feat, x_post, out_lens, log_dur_out, pitch_out, energy_out = self.model.encoder(**sample[\"net_input\"])\n\n        feat = feat.view(bsz, -1, raw_dim)\n        feat = self.generator.gcmvn_denormalize(feat)\n\n        out_lens = out_lens * n_frames_per_step\n        finalized = [\n            {\n                \"waveform\": self.generator.get_waveform(feat[b, :l] if l > 0 else feat.new_zeros([1, raw_dim]))\n            }\n            for b, l in zip(range(bsz), out_lens)\n        ]\n\n        return finalized[0][\"waveform\"], self.task.sr\n    \n    def full_tts(self, text):\n        sample = TTSHubInterface.get_model_input(self.task, text)\n        wav, rate = TTSHubInterface.get_prediction(self.task, self.model, self.generator, sample)\n        return wav, rate\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tts = TTSModel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget \"https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStories-valid.txt?download=true\" -O val_raw.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"val_raw.txt\", 'r', encoding=\"utf-8\") as f:\n    texts = f.readlines()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as ipd\n\nprint(texts[0])\nt = texts[0].replace('.', ',')\nwav, sr = tts.get_wav(tts.simple_change(t, dur_factor=1.))\nipd.Audio(wav, rate=sr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\n\n\nsecret_label = \"wandb_key\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nwandb.login(key=secret_value) \nwandb.init(project=\"fastspeech_audio\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir audio\n!mkdir audio/clean\n!mkdir audio/aug","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nfrom torchaudio import save\n\n\ndurations_factor = np.linspace(2, 5, 13)\nlimit = 10\n\nfor i, t in tqdm(enumerate(texts[:limit])):\n    modified_text = t.replace('.', ',') # этот fastspeech не воспринимает пуктуацию, кроме запятых\n    if ',' in modified_text:\n        wav, sr = tts.get_wav(tts.simple_change(modified_text, dur_factor=1.))\n        wandb.log({\"test audio\": wandb.Audio(wav.numpy(), caption=modified_text, sample_rate=sr)})\n        save(f\"audio/clean/{i}.wav\", wav.unsqueeze(0), sr)\n        \n        dur_factor = np.random.choice(durations_factor)\n        \n        wav, sr = tts.get_wav(tts.simple_change(modified_text, dur_factor=dur_factor))\n        wandb.log({\"aug audio\": wandb.Audio(wav.numpy(), caption=modified_text, sample_rate=sr)})\n        save(f\"audio/aug/{i}.wav\", wav.unsqueeze(0), sr)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar cf audio.tar audio","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}